Namespace(batch_size=128, depth=[784, 400, 400], drop_rate=0.5, epochs=30, evaluate=False, gammas=[0.1, 0.1], log_file='cnn_mnist_lr0.1_wd2e-4.log', lr=0.1, model='cnn_mnist', momentum=0.9, resume='', save_path='./save/cnn_mnist/cnn_mnist_lr0.1_wd2e-4_p0.5/', schedule=[20, 25], use_cuda=True, weight_decay=0.0002)
==> Building model..

Net(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (relu1): ReLU(inplace=True)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (relu2): ReLU(inplace=True)
  (dropout1): Dropout(p=0.5, inplace=False)
  (dropout2): Dropout(p=0.5, inplace=False)
  (fc1): Linear(in_features=9216, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
----  --------  ---------  --------  ----------  ---------  ----------
  ep        lr    tr_loss    tr_acc    val_loss    val_acc    best_acc
----  --------  ---------  --------  ----------  ---------  ----------
   1    0.1000     0.4084   87.3960      0.0851    97.4800     97.4800
   2    0.1000     0.1681   94.9720      0.0527    98.5000     98.5000
   3    0.1000     0.1388   95.8820      0.0474    98.6400     98.6400
   4    0.1000     0.1117   96.6160      0.0462    98.5700     98.6400
   5    0.1000     0.1060   96.8620      0.0436    98.8300     98.8300
   6    0.1000     0.0920   97.2020      0.0441    98.8200     98.8300
   7    0.1000     0.0920   97.2200      0.0440    98.6800     98.8300
   8    0.1000     0.0841   97.5000      0.0403    98.8600     98.8600
   9    0.1000     0.0806   97.6080      0.0415    98.8300     98.8600
  10    0.1000     0.0783   97.6560      0.0361    99.0000     99.0000
  11    0.1000     0.0755   97.7120      0.0395    98.9500     99.0000
  12    0.1000     0.0737   97.7700      0.0338    98.9900     99.0000
  13    0.1000     0.0691   97.8900      0.0378    98.9500     99.0000
  14    0.1000     0.0707   97.8100      0.0344    99.1100     99.1100
  15    0.1000     0.0661   97.8500      0.0345    99.1100     99.1100
  16    0.1000     0.0680   97.9760      0.0385    98.8500     99.1100
  17    0.1000     0.0641   98.0060      0.0387    98.9700     99.1100
  18    0.1000     0.0657   98.0420      0.0383    99.0300     99.1100
  19    0.1000     0.0659   98.0000      0.0377    98.9100     99.1100
  20    0.1000     0.0615   98.0080      0.0317    99.0800     99.1100
  21    0.0100     0.0444   98.6000      0.0304    99.1400     99.1400
  22    0.0100     0.0394   98.7580      0.0290    99.1300     99.1400
  23    0.0100     0.0343   98.9680      0.0295    99.1400     99.1400
  24    0.0100     0.0337   98.9300      0.0295    99.1600     99.1600
  25    0.0100     0.0291   99.0440      0.0293    99.1600     99.1600
  26    0.0010     0.0284   99.1140      0.0295    99.1500     99.1600
  27    0.0010     0.0276   99.1100      0.0295    99.1700     99.1700
  28    0.0010     0.0272   99.1220      0.0296    99.1600     99.1700
  29    0.0010     0.0282   99.0780      0.0297    99.1800     99.1800
  30    0.0010     0.0275   99.0940      0.0293    99.1800     99.1800
Test accuracy: 99.43
