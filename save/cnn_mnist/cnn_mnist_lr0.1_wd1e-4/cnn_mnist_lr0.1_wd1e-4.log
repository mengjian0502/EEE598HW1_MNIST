Namespace(batch_size=128, depth=[784, 400, 400], drop_rate=0.2, epochs=30, evaluate=False, gammas=[0.1, 0.1], log_file='cnn_mnist_lr0.1_wd1e-4.log', lr=0.1, model='cnn_mnist', momentum=0.9, resume='', save_path='./save/cnn_mnist/cnn_mnist_lr0.1_wd1e-4/', schedule=[20, 25], use_cuda=True, weight_decay=0.0001)
==> Building model..

Net(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (relu1): ReLU(inplace=True)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (relu2): ReLU(inplace=True)
  (dropout1): Dropout(p=0.25, inplace=False)
  (dropout2): Dropout(p=0.5, inplace=False)
  (fc1): Linear(in_features=9216, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
----  --------  ---------  --------  ---------  --------  ----------
  ep        lr    tr_loss    tr_acc    te_loss    te_acc    best_acc
----  --------  ---------  --------  ---------  --------  ----------
   1    0.1000     0.3154   90.4450     0.0744   97.7800     97.7800
   2    0.1000     0.1455   95.6783     0.0592   98.2300     98.2300
   3    0.1000     0.1176   96.5817     0.0551   98.3800     98.3800
   4    0.1000     0.0964   97.0900     0.0422   98.5600     98.5600
   5    0.1000     0.0909   97.2933     0.0441   98.6600     98.6600
   6    0.1000     0.0752   97.7133     0.0351   98.7600     98.7600
   7    0.1000     0.0691   97.8950     0.0378   98.8600     98.8600
   8    0.1000     0.0647   97.9983     0.0361   99.0400     99.0400
   9    0.1000     0.0642   98.0800     0.0430   98.7700     99.0400
  10    0.1000     0.0585   98.1550     0.0372   98.9400     99.0400
  11    0.1000     0.0597   98.1100     0.0335   99.0200     99.0400
  12    0.1000     0.0557   98.2933     0.0342   98.8600     99.0400
  13    0.1000     0.0544   98.2900     0.0399   98.8400     99.0400
  14    0.1000     0.0527   98.3717     0.0357   98.9300     99.0400
  15    0.1000     0.0501   98.4367     0.0327   99.0200     99.0400
  16    0.1000     0.0511   98.4600     0.0341   98.8800     99.0400
  17    0.1000     0.0469   98.5233     0.0396   98.9300     99.0400
  18    0.1000     0.0481   98.5300     0.0304   99.0800     99.0800
  19    0.1000     0.0443   98.6233     0.0339   98.9600     99.0800
  20    0.1000     0.0431   98.6300     0.0363   98.9300     99.0800
  21    0.0100     0.0277   99.0783     0.0277   99.2000     99.2000
  22    0.0100     0.0201   99.3233     0.0262   99.2300     99.2300
  23    0.0100     0.0177   99.4283     0.0266   99.2200     99.2300
  24    0.0100     0.0160   99.4350     0.0258   99.2100     99.2300
  25    0.0100     0.0165   99.4533     0.0242   99.2500     99.2500
  26    0.0010     0.0142   99.5300     0.0245   99.2400     99.2500
  27    0.0010     0.0149   99.5183     0.0244   99.2300     99.2500
  28    0.0010     0.0152   99.5017     0.0244   99.2500     99.2500
  29    0.0010     0.0151   99.4900     0.0244   99.2100     99.2500
  30    0.0010     0.0146   99.5333     0.0244   99.2300     99.2500
