Namespace(batch_size=128, depth=[784, 400, 400], drop_rate=0.2, epochs=30, evaluate=False, gammas=[0.1, 0.1], log_file='cnn_mnist_lr0.1_wd1e-4.log', lr=0.1, model='cnn_mnist', momentum=0.9, resume='', save_path='./save/cnn_mnist/cnn_mnist_lr0.1_wd1e-4_p0.2/', schedule=[20, 25], use_cuda=True, weight_decay=0.0001)
==> Building model..

Net(
  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))
  (relu1): ReLU(inplace=True)
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
  (relu2): ReLU(inplace=True)
  (dropout1): Dropout(p=0.2, inplace=False)
  (dropout2): Dropout(p=0.2, inplace=False)
  (fc1): Linear(in_features=4608, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
----  --------  ---------  --------  ----------  ---------  ----------
  ep        lr    tr_loss    tr_acc    val_loss    val_acc    best_acc
----  --------  ---------  --------  ----------  ---------  ----------
   1    0.1000     0.3445   89.5540      0.0705    97.8800     97.8800
   2    0.1000     0.0927   97.1520      0.0609    98.2800     98.2800
   3    0.1000     0.0678   97.9200      0.0455    98.7400     98.7400
   4    0.1000     0.0548   98.2100      0.0448    98.7600     98.7600
   5    0.1000     0.0491   98.4820      0.0465    98.7900     98.7900
   6    0.1000     0.0430   98.6020      0.0521    98.6500     98.7900
   7    0.1000     0.0368   98.8380      0.0420    98.8900     98.8900
   8    0.1000     0.0337   98.8420      0.0420    98.8700     98.8900
   9    0.1000     0.0309   99.0260      0.0480    98.8300     98.8900
  10    0.1000     0.0319   98.9300      0.0357    99.0300     99.0300
  11    0.1000     0.0276   99.0860      0.0423    98.8200     99.0300
  12    0.1000     0.0259   99.1580      0.0395    99.0200     99.0300
  13    0.1000     0.0244   99.1680      0.0468    98.8300     99.0300
  14    0.1000     0.0239   99.1620      0.0446    98.9800     99.0300
  15    0.1000     0.0213   99.2980      0.0403    98.9800     99.0300
  16    0.1000     0.0199   99.3240      0.0464    99.0000     99.0300
  17    0.1000     0.0195   99.3420      0.0494    98.9400     99.0300
  18    0.1000     0.0192   99.3720      0.0367    99.1300     99.1300
  19    0.1000     0.0208   99.3340      0.0493    98.8100     99.1300
  20    0.1000     0.0182   99.3920      0.0362    99.0700     99.1300
  21    0.0100     0.0104   99.6560      0.0335    99.1900     99.1900
  22    0.0100     0.0072   99.7500      0.0334    99.2400     99.2400
  23    0.0100     0.0063   99.7980      0.0343    99.2100     99.2400
  24    0.0100     0.0062   99.7820      0.0351    99.2100     99.2400
  25    0.0100     0.0055   99.8080      0.0364    99.2300     99.2400
  26    0.0010     0.0045   99.8740      0.0358    99.2500     99.2500
  27    0.0010     0.0051   99.8500      0.0355    99.2600     99.2600
  28    0.0010     0.0049   99.8420      0.0355    99.2600     99.2600
  29    0.0010     0.0055   99.7960      0.0351    99.2700     99.2700
  30    0.0010     0.0053   99.8260      0.0349    99.2600     99.2700
Test accuracy: 99.28
